import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from scipy.stats import t, binomtest
from scipy import stats

st.set_page_config(page_title="Previs√£o da Turbidez da √Ågua", layout="wide")
st.title("üíß Estudo da Turbidez da √Ågua ao Longo do Tempo")
st.markdown("### üßæ Estrutura do Dataset e Classifica√ß√£o das Vari√°veis")

# Mapeamento manual de classifica√ß√£o estat√≠stica
classificacao_variaveis = {
    "data de amostragem": "Qualitativa ordinal",
    "turbidez": "Quantitativa cont√≠nua",
    "periodo": "Qualitativa nominal",
    "ano decimal": "Quantitativa cont√≠nua",
    "s√≥lidos totais": "Quantitativa cont√≠nua",
    'esta√ß√£o': 'Qualitativa nominal'
}

# Criar tabela de classifica√ß√£o
tabela_variaveis = pd.DataFrame({
    "Vari√°vel": list(classificacao_variaveis.keys()),
    "Tipo Estat√≠stico": list(classificacao_variaveis.values())
})

st.dataframe(tabela_variaveis, use_container_width=True)

st.markdown("""
As vari√°veis foram classificadas de acordo com sua natureza estat√≠stica:

- **Qualitativa nominal:** categorias sem ordem definida (ex: per√≠odo).
- **Qualitativa ordinal:** categorias com ordem (ex: tempo).
- **Quantitativa cont√≠nua:** n√∫meros reais que admitem fra√ß√µes (ex: turbidez, ano decimal).
""")

st.markdown("""
### üìò O que √© Turbidez?

A **turbidez** √© uma medida da quantidade de part√≠culas s√≥lidas em suspens√£o na √°gua que afetam sua transpar√™ncia.  
Ela √© normalmente causada por argilas, siltes, mat√©ria org√¢nica, algas ou outros materiais.

- A unidade de medida usada √© **NTU (Unidade Nefelom√©trica de Turbidez)**.
- Segundo a legisla√ß√£o brasileira e padr√µes internacionais, **valores abaixo de 5 NTU** s√£o considerados **excelentes** para √°gua pot√°vel.

---

### üîç Objetivo do Estudo

Este painel analisa dados hist√≥ricos de turbidez da √°gua coletados entre 2019 e 2021.  
Aplicamos uma **regress√£o linear** para prever quando os n√≠veis de turbidez podem voltar a padr√µes **excelentes**.
""")

# === Carregamento dos dados ===
@st.cache_data
def carregar_dados():
    arquivos = {
        "2019": "dados/seriehistorica2019.xlsx",
        "1S2020": "dados/primeirosemestre2020.xlsx",
        "2S2020": "dados/segundosemestre2020.xlsx",
        "2021": "dados/ano2021.xlsx"
    }
    lista_dfs = []

    for nome, caminho in arquivos.items():
        df = pd.read_excel(caminho)
        df.columns = df.columns.str.strip().str.lower()

        colunas_interesse = ['data de amostragem', 'turbidez', 's√≥lidos totais', 'solidos totais','esta√ß√£o']
        colunas_presentes = [col for col in colunas_interesse if col in df.columns]

        if 'data de amostragem' in colunas_presentes:
            dados = df[colunas_presentes].copy()
            dados['data de amostragem'] = pd.to_datetime(dados['data de amostragem'], errors='coerce')
            dados = dados.dropna(subset=['data de amostragem'])
            dados['periodo'] = nome
            lista_dfs.append(dados)

    return pd.concat(lista_dfs, ignore_index=True)

df = carregar_dados()

# Padronizar nome da coluna de s√≥lidos totais
df = df.rename(columns={'solidos totais': 's√≥lidos totais'})

# === Pr√©-processamento ===
df = df.sort_values(by='data de amostragem')
df['ano_decimal'] = df['data de amostragem'].dt.year + (df['data de amostragem'].dt.dayofyear / 365)

# === NOVAS FUN√á√ïES ===
def intervalo_previsao(X, y, modelo, alfa=0.05):
    """Calcula intervalo de previs√£o para regress√£o linear"""
    pred = modelo.predict(X)
    n = len(y)
    mse = np.sum((y - pred) ** 2) / (n - 2)
    h = np.diag(X @ np.linalg.pinv(X.T @ X) @ X.T)
    erro = np.sqrt(mse * (1 + h))
    t_val = t.ppf(1 - alfa/2, n-2)
    return pred - t_val * erro, pred + t_val * erro

def plot_residuos(y_real, y_pred):
    residuos = y_real - y_pred
    fig = px.scatter(x=y_pred, y=residuos,
                    labels={'x': 'Valores Preditos', 'y': 'Res√≠duos'},
                    title="An√°lise de Res√≠duos")
    fig.add_hline(y=0, line_dash="dash")
    return fig

# === MODELAGEM AVAN√áADA ===
st.header("üìà Modelos de Previs√£o de Turbidez")

# Sele√ß√£o do tipo de modelo
model_type = st.radio("Tipo de Modelo:", 
                     ["Linear", "Polinomial (Grau 2)"], 
                     horizontal=True)

# Preparar dados
df_modelo = df[['ano_decimal', 'turbidez']].dropna()
X = df_modelo[['ano_decimal']].values
y = df_modelo['turbidez'].values

# Ajustar modelo selecionado
if model_type == "Linear":
    modelo = LinearRegression()
    modelo.fit(X, y)
else:
    # Modelo polinomial
    modelo = make_pipeline(
        PolynomialFeatures(degree=2),
        LinearRegression()
    )
    modelo.fit(X, y)

# Previs√£o para anos futuros
anos_futuros = np.arange(2019, 2031, 0.1).reshape(-1, 1)
previsoes = modelo.predict(anos_futuros)

# Calcular intervalos de confian√ßa
if model_type == "Linear":
    ic_lower, ic_upper = intervalo_previsao(X, y, modelo)
else:
    # Para modelo polinomial, usamos um intervalo simplificado
    ic_lower = previsoes - 1.96 * np.std(y - modelo.predict(X))
    ic_upper = previsoes + 1.96 * np.std(y - modelo.predict(X))

# Criar datas reais para eixo X
datas_futuras = pd.to_datetime([f"{int(a)}-01-01" for a in anos_futuros.flatten()])

# === Gr√°fico de Previs√£o ===
fig = go.Figure()

# Pontos reais
fig.add_trace(go.Scatter(
    x=df['data de amostragem'], 
    y=df['turbidez'],
    mode='markers', 
    name='Amostras', 
    marker=dict(color='blue', size=5)
))

# Linha de regress√£o
fig.add_trace(go.Scatter(
    x=datas_futuras, 
    y=previsoes,
    mode='lines', 
    name=f'Tend√™ncia ({model_type})', 
    line=dict(color='red')
))

# Intervalo de confian√ßa
fig.add_trace(go.Scatter(
    x=datas_futuras, 
    y=ic_lower,
    fill=None, 
    mode='lines', 
    line=dict(width=0),
    showlegend=False
))
fig.add_trace(go.Scatter(
    x=datas_futuras, 
    y=ic_upper,
    fill='tonexty', 
    mode='lines', 
    line=dict(width=0),
    name='Intervalo 95%'
))

# Linha padr√£o excelente
fig.add_hline(
    y=5, 
    line_dash="dash", 
    line_color="green",
    annotation_text="Padr√£o Excelente (5 NTU)", 
    annotation_position="bottom right"
)

fig.update_layout(
    title="Turbidez da √Ågua ao Longo do Tempo",
    xaxis_title="Data", 
    yaxis_title="Turbidez (NTU)",
    height=500
)

st.plotly_chart(fig, use_container_width=True)

# === Previs√£o de retorno √† qualidade excelente ===
ano_excelente = None
for ano, pred in zip(anos_futuros.flatten(), previsoes):
    if pred <= 5:
        ano_excelente = ano
        break

st.subheader("üìà Previs√£o com Base na Tend√™ncia Atual")

if ano_excelente:
    st.success(f"""
    ‚úÖ A an√°lise de regress√£o {model_type.lower()} prev√™ que a turbidez pode atingir o padr√£o excelente (**‚â§ 5 NTU**) 
    por volta de **{int(ano_excelente)}**.
    """)
else:
    st.warning("‚ö†Ô∏è A proje√ß√£o atual indica que os n√≠veis de turbidez podem n√£o atingir o padr√£o excelente at√© 2030.")

# === AN√ÅLISE DE RES√çDUOS ===
st.header("üîç Diagn√≥stico do Modelo")
y_pred = modelo.predict(X)
fig_resid = plot_residuos(y, y_pred)
st.plotly_chart(fig_resid, use_container_width=True)

# === AN√ÅLISE BINOMIAL ===
st.header("üìä An√°lise Binomial de Conformidade")
limite_turbidez = st.slider("Limite de Turbidez (NTU) para conformidade:", 
                           min_value=1.0, max_value=20.0, value=5.0, step=0.5)

df['conforme'] = df['turbidez'] <= limite_turbidez
conformidade_por_ano = df.groupby(df['data de amostragem'].dt.year)['conforme'].mean().reset_index()

fig_binom = px.bar(conformidade_por_ano, 
                  x='data de amostragem', 
                  y='conforme',
                  title=f"Propor√ß√£o de Amostras Conforme (‚â§ {limite_turbidez} NTU)",
                  labels={'conforme': 'Propor√ß√£o Conforme', 'data de amostragem': 'Ano'})
st.plotly_chart(fig_binom, use_container_width=True)

# Teste binomial
total_amostras = len(df['conforme'].dropna())
amostras_conformes = sum(df['conforme'].dropna())
result = binomtest(amostras_conformes, total_amostras, 0.95)  # H0: p=95% de conformidade

st.metric("Teste Binomial", 
         f"p-value = {result.pvalue:.4f}",
         help="H0: Propor√ß√£o de amostras conforme = 95%")

# === CORRELA√á√ÉO ENTRE VARI√ÅVEIS ===
st.header("üîó Correla√ß√£o entre Turbidez e S√≥lidos Totais")
if 's√≥lidos totais' in df.columns:
    df_corr = df[['turbidez', 's√≥lidos totais']].dropna()
    fig_corr = px.scatter(
        df_corr, 
        x='s√≥lidos totais', 
        y='turbidez',
        trendline="ols",
        title="Rela√ß√£o entre Turbidez e S√≥lidos Totais",
        labels={'s√≥lidos totais': 'S√≥lidos Totais (mg/L)', 'turbidez': 'Turbidez (NTU)'}
    )
    st.plotly_chart(fig_corr, use_container_width=True)
    
    # Calcular coeficiente de correla√ß√£o
    corr_coef = np.corrcoef(df_corr['s√≥lidos totais'], df_corr['turbidez'])[0,1]
    st.metric("Coeficiente de Correla√ß√£o de Pearson", f"{corr_coef:.2f}")

# [RESTANTE DO C√ìDIGO ORIGINAL MANTIDO...]
st.header("üß™ Evolu√ß√£o dos S√≥lidos Totais (STD)")

if 's√≥lidos totais' in df.columns:
    std_data = df[['data de amostragem', 's√≥lidos totais']].dropna()

    fig_std = go.Figure()
    fig_std.add_trace(go.Scatter(
        x=std_data['data de amostragem'],
        y=std_data['s√≥lidos totais'],
        mode='lines+markers',
        name='STD',
        line=dict(color='purple')
    ))

    fig_std.update_layout(
        title="Concentra√ß√£o de S√≥lidos Totais ao Longo do Tempo",
        xaxis_title="Data",
        yaxis_title="Concentra√ß√£o de STD (mg/L)",
        height=500
    )

    st.plotly_chart(fig_std, use_container_width=True)
else:
    st.info("‚ö†Ô∏è Nenhuma informa√ß√£o sobre s√≥lidos totais foi encontrada nos dados carregados.")

# === Filtragem e gr√°fico das esta√ß√µes RD074, RD075, RD009 ===
estacoes_interesse = ['RD074', 'RD075', 'RD009']

st.header("Mapa das esta√ß√µes de coleta")
st.image('assets\download.png')
st.write('Declararemos as esta√ß√µes RD074, RD075 e RD009 como esta√ß√µes de interesse para o nosso estudo, devido a sua proximidade a barragem rompida')

# Filtrar os dados para as esta√ß√µes de interesse e as demais
df_estacoes_interesse = df[df['esta√ß√£o'].isin(estacoes_interesse)]
df_outros = df[~df['esta√ß√£o'].isin(estacoes_interesse)]

# Gr√°fico para comparar s√≥lidos totais nas esta√ß√µes de interesse com as demais
st.header("üìä Compara√ß√£o dos S√≥lidos Totais nas Esta√ß√µes RD074, RD075, RD009 com as Demais")

# Criar o gr√°fico
fig_comparacao = go.Figure()

# Esta√ß√µes de interesse
fig_comparacao.add_trace(go.Box(
    y=df_estacoes_interesse['s√≥lidos totais'],
    x=df_estacoes_interesse['esta√ß√£o'],
    name='Esta√ß√µes de Interesse (RD074, RD075, RD009)',
    boxmean='sd',
    marker=dict(color='orange')
))

# Outras esta√ß√µes
fig_comparacao.add_trace(go.Box(
    y=df_outros['s√≥lidos totais'],
    x=df_outros['esta√ß√£o'],
    name='Outras Esta√ß√µes',
    boxmean='sd',
    marker=dict(color='blue')
))

fig_comparacao.update_layout(
    title="Distribui√ß√£o dos S√≥lidos Totais por Esta√ß√£o",
    xaxis_title="Esta√ß√£o",
    yaxis_title="S√≥lidos Totais (mg/L)",
    height=500
)

st.plotly_chart(fig_comparacao, use_container_width=True)

# === An√°lise estat√≠stica (Intervalos de Confian√ßa e Teste T) ===
def intervalo_confianca(data, confidence=0.95):
    n = len(data)
    mean = np.mean(data)
    sem = stats.sem(data)
    margin_of_error = sem * t.ppf((1 + confidence) / 2., n-1)
    return mean - margin_of_error, mean + margin_of_error, mean

# Intervalo de confian√ßa para as esta√ß√µes de interesse
ic_interesse_lower, ic_interesse_upper, mean_interesse = intervalo_confianca(df_estacoes_interesse['s√≥lidos totais'])

# Intervalo de confian√ßa para as outras esta√ß√µes
ic_outros_lower, ic_outros_upper, mean_outros = intervalo_confianca(df_outros['s√≥lidos totais'])

# Exibir intervalos de confian√ßa
st.subheader("üìä Intervalo de Confian√ßa para a M√©dia de S√≥lidos Totais")
st.write(f"**Esta√ß√µes de Interesse (RD074, RD075, RD009):**")
st.write(f"M√©dia: {mean_interesse:.2f} mg/L")
st.write(f"Intervalo de Confian√ßa (95%): ({ic_interesse_lower:.2f}, {ic_interesse_upper:.2f}) mg/L")

st.write(f"**Outras Esta√ß√µes:**")
st.write(f"M√©dia: {mean_outros:.2f} mg/L")
st.write(f"Intervalo de Confian√ßa (95%): ({ic_outros_lower:.2f}, {ic_outros_upper:.2f}) mg/L")

# Teste t para compara√ß√£o de m√©dias
t_stat, p_value = stats.ttest_ind(df_estacoes_interesse['s√≥lidos totais'].dropna(), df_outros['s√≥lidos totais'].dropna())

st.subheader("üî¨ Teste T para Compara√ß√£o de M√©dias")
st.write(f"**Estat√≠stica t:** {t_stat:.2f}")
st.write(f"**Valor p:** {p_value:.4f}")

if p_value < 0.05:
    st.success("üìâ Existe uma diferen√ßa estatisticamente significativa entre os s√≥lidos totais das esta√ß√µes de interesse (RD074, RD075, RD009) e as demais.")
else:
    st.info("üìà N√£o existe uma diferen√ßa estatisticamente significativa entre os s√≥lidos totais das esta√ß√µes de interesse e as demais.")

st.write('Nota-se que, atuando com um intervalo de confian√ßa de 95%, as m√©dias dos s√≥lidos totais presentes nas amostras coletadas pelas esta√ß√µes de interesse ainda s√£o quase metade dos valores compar√°veis coletados nas demais esta√ß√µes.')
st.write('Isso pode evidenciar uma maior preocupa√ß√£o com a remo√ß√£o dos dejetos no local de rompimento da barragem')